{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "import time\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import f1_score\n",
    "import os \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import  Pool\n",
    "from functools import partial\n",
    "from sklearn.decomposition import PCA\n",
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "batch_size = 512\n",
    "max_features = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(x):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text    = re.sub(pattern, ' ', x)\n",
    "    return text\n",
    "\n",
    "def clean_numbers(x):\n",
    "    if bool(re.search(r'\\d', x)):\n",
    "        x = re.sub('[0-9]{5,}', '#####', x)\n",
    "        x = re.sub('[0-9]{4}', '####', x)\n",
    "        x = re.sub('[0-9]{3}', '###', x)\n",
    "        x = re.sub('[0-9]{2}', '##', x)\n",
    "        x = re.sub('[0-9]{1}', '', x)\n",
    "    return x\n",
    "\n",
    "\n",
    "mapping = {'gk': 'tidak', 'ga': 'tidak', 'gak': 'tidak', 'tdk': 'tidak', 'sm': 'sama', \n",
    "             'sma': 'sama', 'disruh': 'disuruh', 'yg': 'yang', 'dr':'dari', 'dri': 'dari', \n",
    "             'udh': 'sudah', 'sdh': 'sudah', 'knp': 'kenapa', 'pdhl': 'padahal', 'tp': 'tapi',\n",
    "             'tpi': 'tapi', 'pd': 'pada', 'td': 'tadi', 'tdi': 'tadi'}\n",
    "\n",
    "\n",
    "def replace_norms(text):\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(mapping.keys()) + r')\\b')\n",
    "    return pattern.sub(lambda x: mapping[x.group()], text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessing.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "    \n",
    "with open('encoder.pickle', 'rb') as handle:\n",
    "    le = pickle.load(handle)\n",
    "    \n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "with open('wordembedd.pickle', 'rb') as handle:\n",
    "    embedding_matrix = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = 64\n",
    "        drp = 0.1\n",
    "        n_classes = len(le.classes_)\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(embed_size, self.hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size*4 , 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "        self.out = nn.Linear(64, n_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #rint(x.size())\n",
    "        h_embedding = self.embedding(x)\n",
    "        #_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        avg_pool = torch.mean(h_lstm, 1)\n",
    "        max_pool, _ = torch.max(h_lstm, 1)\n",
    "        conc = torch.cat(( avg_pool, max_pool), 1)\n",
    "        conc = self.relu(self.linear(conc))\n",
    "        conc = self.dropout(conc)\n",
    "        out = self.out(conc)\n",
    "        return out\n",
    "model = BiLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('rnn_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (embedding): Embedding(9000, 300)\n",
       "  (lstm): LSTM(300, 64, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (out): Linear(in_features=64, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(x):    \n",
    "    # lower the text\n",
    "    x = x.lower()\n",
    "    # Clean the text\n",
    "    x =  clean_text(x)\n",
    "    # Clean numbers\n",
    "    x =  clean_numbers(x)\n",
    "    # Clean Contractions\n",
    "    x = replace_norms(x)\n",
    "    print(x)\n",
    "    # tokenize\n",
    "    x = tokenizer.texts_to_sequences([x])\n",
    "    # pad\n",
    "    x = pad_sequences(x, maxlen=600)\n",
    "    # create dataset\n",
    "    x = torch.tensor(x, dtype=torch.long)\n",
    "\n",
    "    pred = model(x).detach()\n",
    "    pred = F.softmax(pred).cpu().numpy()\n",
    "\n",
    "    pred = pred.argmax(axis=1)\n",
    "\n",
    "    pred = le.classes_[pred]\n",
    "\n",
    "    return 'Kategori:'+pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admin    kenapa akhir ini kalo saya sudah pesan go ride pake gopay pula  saya kok tidak dapat point ya   mohon bantuannya   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\skripsienv\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Kategori:Aplikasi'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_single(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}